{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181e235d-06c1-4b0d-b714-ef59ef8410bb",
   "metadata": {},
   "source": [
    "# Music Genera Classification With the GTZAN dataset\n",
    "CS345 Fall 2024 Project   \n",
    "Wade McCaulley  \n",
    "Jacob Ingraham  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ce2c5-e32c-4b8e-a55b-ecb3acc9460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc4e79-3859-4bcb-9e02-c04b647c2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_30_seconds_filepath = \"../Data/features_30_sec.csv\"\n",
    "features_3_seconds_filepath = \"../Data/features_3_sec.csv\"\n",
    "mel_spectrograms_filepath = \"../Data/images_original\"\n",
    "\n",
    "genres = [\"blues\", \"classical\" , \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f4bc1-2f5d-4cfa-a837-2a3ce5d17674",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loads the CSVs. Features are everything but the first col(filename), and the lables. The lables are the last column''' \n",
    "def loadCSVs(filepath):\n",
    "    data = pd.read_csv(filepath, dtype = object, delimiter = ',').values\n",
    "    X = data[:,2:-1]\n",
    "    y = data[:,-1:]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f664227-1b71-494d-abea-47dfa3d340a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This will turn the genere lables into np.array of ints'''\n",
    "def lable_to_int(lables, genres):\n",
    "    lable_int = np.array(lables)\n",
    "    for i in range(len(genres)):\n",
    "        lable_int[lable_int==genres[i]]=i\n",
    "    return lable_int \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3e3d7-b630-486c-b4de-df74a1dec118",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#this will turn the png where each pixel is represented by 4 values into a single value. The first three are colors, and I think the forth is transparancy.'''\n",
    "def gray_scale_images(images):\n",
    "    gray_images = np.dot(images[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    return np.array(gray_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb525d5-d3cf-43a6-947b-974aff3e4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loads the mel spectrograms into a np array of images. Each image is 288, 432 pixels, and each pixel is represented by four values'''\n",
    "def load_mel_spectrograms():\n",
    "    image_features = []\n",
    "    image_lables = []\n",
    "    for genre in genres:\n",
    "        print(\"Loading\", genre)\n",
    "        images_file_path = mel_spectrograms_filepath + \"/\" + genre\n",
    "        png_files = [f for f in os.listdir(images_file_path) if f.endswith('.png')]\n",
    "\n",
    "        for file in png_files:\n",
    "            file_path = images_file_path +\"/\"+ file\n",
    "            image = plt.imread(file_path)  # Load the image\n",
    "            image_features.append(image)\n",
    "            image_lables.append(genre)\n",
    "\n",
    "    return np.array(image_features), np.array(image_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea624ba4-f7df-44e0-920c-4bec63122ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_X_30sec, y_30sec = loadCSVs(features_30_seconds_filepath)\n",
    "X_30sec = string_X_30sec.astype(np.float64)\n",
    "string_X_3sec, y_3sec = loadCSVs(features_3_seconds_filepath)\n",
    "X_3sec = string_X_3sec.astype(np.float64)\n",
    "\n",
    "# reshape y to a 1d array\n",
    "y_30sec = y_30sec.ravel()\n",
    "y_3sec = y_3sec.ravel()\n",
    "\n",
    "print(X_30sec.shape, y_30sec.shape)\n",
    "print(X_3sec.shape, y_3sec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e833a67-c7af-4aac-b059-fafbcac845eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images, y_images = load_mel_spectrograms()\n",
    "y_images = lable_to_int(y_images,genres)\n",
    "X_images.shape, y_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_images_train, X_images_temp, y_images_train, y_images_temp = train_test_split(X_images, y_images, test_size=0.2, shuffle=True, random_state=7)\n",
    "X_images_val, X_images_test, y_images_val, y_images_test = train_test_split(X_images_temp, y_images_temp, test_size=0.5, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240058da-7c2b-4ef8-aadc-9a79df7d1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grayscale images \n",
    "X_images_gray = gray_scale_images(X_images)\n",
    "X_images_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fab7f-0d3b-4598-98f7-503e461ecfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_int = lable_to_int(y_30sec, genres)\n",
    "y_3sec_int = lable_to_int(y_3sec, genres)\n",
    "y_images_int = lable_to_int(y_images, genres)\n",
    "y_30sec_int.shape, y_3sec_int.shape, y_images_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7eb730-7c49-46a8-ba43-90d96b6354e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create normalized and standardized versions of data'''\n",
    "X_30sec_norm = (X_30sec-np.min(X_30sec, axis=0))/(np.max(X_30sec,axis=0)-np.min(X_30sec,axis=0))\n",
    "X_3sec_norm = (X_3sec-np.min(X_3sec, axis=0))/(np.max(X_3sec,axis=0)-np.min(X_3sec,axis=0))\n",
    "X_30sec_std = (X_30sec-np.mean(X_30sec, axis=0))/(np.std(X_30sec, axis=0))\n",
    "X_3sec_std = (X_3sec-np.mean(X_3sec, axis=0))/(np.std(X_3sec, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check norm and std data'''\n",
    "print(np.max(X_30sec_norm)==1,np.min(X_30sec_norm)==0)\n",
    "print(np.max(X_3sec_norm)==1,np.min(X_3sec_norm)==0)\n",
    "print(np.mean(X_30sec_std), np.std(X_30sec_std))\n",
    "print(np.mean(X_3sec_std), np.std(X_3sec_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29eb03-d02c-4959-acbd-c26ad1c8af85",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5e714-32ce-470f-86d6-a33a23a768ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb6aea-915a-4cf9-89b4-e8d8aa9d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def girdSearchClassifier(model, features, labels, paramgrid):\n",
    "    start_time = time.time()\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    classifier = GridSearchCV(model, paramgrid)\n",
    "    classifier.fit(features, labels)\n",
    "    accuracies = cross_val_score(classifier.best_estimator_, features, labels, cv=cv, \n",
    "                           scoring='accuracy')\n",
    "    accuracy = np.mean(accuracies)\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    return classifier.best_estimator_, accuracy, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a72e48-78da-46e4-87c1-4a51240ec4c0",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f13fe-b3df-417b-912c-5afa7531741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a place holder if we want to do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed679947-de17-4120-8bd7-e6297157328b",
   "metadata": {},
   "source": [
    "## Nearest Neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097809fc-47cc-431c-82f7-e137e4a62e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def testKNN(features, labels, paramgrid):\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    best_estimator, accuracy, run_time = girdSearchClassifier(model, features, labels, paramgrid)\n",
    "    \n",
    "    return best_estimator.get_params()['n_neighbors'], accuracy, run_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9da613-8225-464e-96a5-478f26b138dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': [1,2,4,8,16,32,64,128, 256, 512]\n",
    "}\n",
    "print(\"knn run csv 30sec\")\n",
    "knn_csv30sec_best_estimator, knn_csv30sec_accuracy, knn_csv30sec_time = testKNN(X_30sec, y_30sec, knn_param_grid)\n",
    "\n",
    "print(\"run csv 30sec norm\")\n",
    "knn_csv30sec_norm_best_estimator, knn_csv30sec_norm_accuracy, knn_csv30sec_norm_time = testKNN(X_30sec_norm, y_30sec, knn_param_grid)\n",
    "\n",
    "print(\"run csv 30sec std\")\n",
    "knn_csv30sec_std_best_estimator, knn_csv30sec_std_accuracy, knn_csv30sec_std_time = testKNN(X_30sec_std, y_30sec, knn_param_grid)\n",
    "\n",
    "print(\"run csv 3sec\")\n",
    "knn_csv3sec_best_estimator, knn_csv3sec_accuracy, knn_csv3sec_time = testKNN(X_3sec, y_3sec, knn_param_grid)\n",
    "\n",
    "print(\"run csv 3sec norm\")\n",
    "knn_csv3sec_norm_best_estimator, knn_csv3sec_norm_accuracy, knn_csv3sec_norm_time = testKNN(X_3sec_norm, y_3sec, knn_param_grid)\n",
    "\n",
    "print(\"run csv 3sec std\")\n",
    "knn_csv3sec_std_best_estimator, knn_csv3sec_std_accuracy, knn_csv3sec_std_time = testKNN(X_3sec_std, y_3sec, knn_param_grid)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Dataset\": [\"Features 30 sec\", \"Features 30 sec norm\", \"Features 30 sec std\", \"Features 3 sec\", \"Features 3 sec norm\", \"Features 3 sec std\"],\n",
    "    \"Best n_neighbors\": [\n",
    "        knn_csv30sec_best_estimator,\n",
    "        knn_csv30sec_norm_best_estimator,\n",
    "        knn_csv30sec_std_best_estimator,\n",
    "        knn_csv3sec_best_estimator,\n",
    "        knn_csv3sec_norm_best_estimator,\n",
    "        knn_csv3sec_std_best_estimator\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        knn_csv30sec_accuracy,\n",
    "        knn_csv30sec_norm_accuracy,\n",
    "        knn_csv30sec_std_accuracy,\n",
    "        knn_csv3sec_accuracy,\n",
    "        knn_csv3sec_norm_accuracy,\n",
    "        knn_csv3sec_std_accuracy\n",
    "    ],\n",
    "    \"Run Time\": [\n",
    "        knn_csv30sec_time,\n",
    "        knn_csv30sec_norm_time,\n",
    "        knn_csv30sec_std_time,\n",
    "        knn_csv3sec_time,\n",
    "        knn_csv3sec_norm_time,\n",
    "        knn_csv3sec_std_time\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11292423-e20e-40c5-9613-7e4eb213dfe9",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b05e8c-8b59-4319-a1f8-4b2e4dfea834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def testSVM(features, labels, paramgrid):\n",
    "    X_standard_scaler = StandardScaler().fit(features)\n",
    "    features = X_standard_scaler.transform(features)\n",
    "    model = svm.SVC(kernel=\"linear\")\n",
    "    best_estimator, accuracy, run_time = girdSearchClassifier(model, features, labels, paramgrid)\n",
    "    \n",
    "    return best_estimator.get_params()['C'], best_estimator.get_params()['gamma'], accuracy, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279672f4-a1bc-45f7-9cde-0edd01bdcf05",
   "metadata": {},
   "source": [
    "### Features 3 seconds to large a dataset. Quadratic run time for larger data sets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338aeef-87cc-488d-8046-df03b2469a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_3sec, y_3sec, test_size = 0.01, random_state = 1)\n",
    "sizes = [100, 250, 500, 1000, 2500, 5000, 9000]\n",
    "\n",
    "linear_runtimes = []\n",
    "rbf_runtimes = []\n",
    "\n",
    "X_standard_scaler = StandardScaler().fit(X_train)\n",
    "X_train = X_standard_scaler.transform(X_train)\n",
    "for s in sizes:\n",
    "    start_time = time.time()\n",
    "    classifier = svm.SVC(C = 10, kernel='linear')\n",
    "    classifier.fit(X_train[:s], y_train[:s])\n",
    "    run_time = time.time() - start_time\n",
    "    linear_runtimes.append(run_time)\n",
    "\n",
    "\n",
    "\n",
    "for s in sizes:\n",
    "    start_time = time.time()\n",
    "    classifier = svm.SVC(C = 10, gamma = .1, kernel='rbf')\n",
    "    classifier.fit(X_train[:s], y_train[:s])\n",
    "    run_time = time.time() - start_time\n",
    "    rbf_runtimes.append(run_time)\n",
    "\n",
    "\n",
    "\n",
    "np_linear_runtimes = np.array(linear_runtimes)*5*5*5\n",
    "np_rbf_runtimes = np.array(rbf_runtimes)*5*5*5*5\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(sizes, np_linear_runtimes, label = 'linear SVM')\n",
    "plt.scatter(sizes, np_rbf_runtimes, label = 'rbf SVM')\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('time to run grid search')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecb37c-5c82-4793-b725-8b257812bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gammas = np.logspace(-5, 2, num=8, endpoint=True, base=10.0)\n",
    "#Cs = np.logspace(-2, 4, num =7, endpoint=True, base=10.0)\n",
    "gammas = [.001, .01, 1, 10, 100]\n",
    "Cs = [1, .01, .1, 1, 10]\n",
    "\n",
    "rbf_svm_param_grid = [\n",
    "  {'C': Cs, \n",
    "   'gamma': gammas, \n",
    "   'kernel': ['rbf']},\n",
    " ]\n",
    "linear_svm_param_grid = [\n",
    "  {'C': Cs, \n",
    "   'kernel': ['linear']},\n",
    " ]\n",
    "\n",
    "print(\"run csv 30sec\")\n",
    "rbf_svm_csv30sec_best_estimator_c, rbf_svm_csv30sec_best_estimator_gamma, rbf_svm_csv30sec_accuracy, rbf_svm_csv30sec_time = testSVM(\n",
    "    X_30sec, y_30sec, rbf_svm_param_grid)\n",
    "\n",
    "print(\"run csv 30sec norm\")\n",
    "rbf_svm_csv30sec_norm_best_estimator_c, rbf_svm_csv30sec_norm_best_estimator_gamma, rbf_svm_csv30sec_norm_accuracy, rbf_svm_csv30sec_norm_time = testSVM(\n",
    "    X_30sec_norm, y_30sec, rbf_svm_param_grid)\n",
    "\n",
    "print(\"run csv 30sec std\")\n",
    "rbf_svm_csv30sec_std_best_estimator_c, rbf_svm_csv30sec_std_best_estimator_gamma, rbf_svm_csv30sec_std_accuracy, rbf_svm_csv30sec_std_time = testSVM(\n",
    "    X_30sec_std, y_30sec, rbf_svm_param_grid)\n",
    "\n",
    "print(\"run csv 30sec linear\")\n",
    "svm_csv30sec_best_estimator_c, svm_csv30sec_best_estimator_gamma, svm_csv30sec_accuracy, svm_csv30sec_time = testSVM(\n",
    "    X_30sec, y_30sec, linear_svm_param_grid)\n",
    "\n",
    "print(\"run csv 30sec norm linear\")\n",
    "svm_csv30sec_norm_best_estimator_c, svm_csv30sec_norm_best_estimator_gamma, svm_csv30sec_norm_accuracy, svm_csv30sec_norm_time = testSVM(\n",
    "    X_30sec_norm, y_30sec, linear_svm_param_grid)\n",
    "\n",
    "print(\"run csv 30sec std linear\")\n",
    "svm_csv30sec_std_best_estimator_c, svm_csv30sec_std_best_estimator_gamma, svm_csv30sec_std_accuracy, svm_csv30sec_std_time = testSVM(\n",
    "    X_30sec_std, y_30sec, linear_svm_param_grid)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Dataset\": [\"Features 30 sec\", \"Features 30 sec norm\", \"Features 30 sec std\", \"Features 30 sec\", \"Features 30 sec norm\", \"Features 30 sec std\"],\n",
    "    \"Kernal\": [\"rbf\", \"rbf\", \"rbf\", \"linear\", \"linear\", \"linear\"],\n",
    "    \"Best C\": [\n",
    "        rbf_svm_csv30sec_best_estimator_c,\n",
    "        rbf_svm_csv30sec_norm_best_estimator_c,\n",
    "        rbf_svm_csv30sec_std_best_estimator_c,\n",
    "        svm_csv30sec_best_estimator_c,\n",
    "        svm_csv30sec_norm_best_estimator_c,\n",
    "        svm_csv30sec_std_best_estimator_c\n",
    "    ],\n",
    "    \"Best gamma\": [\n",
    "        rbf_svm_csv30sec_best_estimator_gamma,\n",
    "        rbf_svm_csv30sec_norm_best_estimator_gamma,\n",
    "        rbf_svm_csv30sec_std_best_estimator_gamma,\n",
    "        svm_csv30sec_best_estimator_gamma,\n",
    "        svm_csv30sec_norm_best_estimator_gamma,\n",
    "        svm_csv30sec_std_best_estimator_gamma\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        rbf_svm_csv30sec_accuracy,\n",
    "        rbf_svm_csv30sec_norm_accuracy,\n",
    "        rbf_svm_csv30sec_std_accuracy,\n",
    "        svm_csv30sec_accuracy,\n",
    "        svm_csv30sec_norm_accuracy,\n",
    "        svm_csv30sec_std_accuracy\n",
    "    ],\n",
    "    \"Run Time\": [\n",
    "        rbf_svm_csv30sec_time,\n",
    "        rbf_svm_csv30sec_norm_time,\n",
    "        rbf_svm_csv30sec_std_time,\n",
    "        svm_csv30sec_time,\n",
    "        svm_csv30sec_norm_time,\n",
    "        svm_csv30sec_std_time\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947bcd2-18da-4039-a8b9-2242f825150a",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ea54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TensorFlow setup'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40a7f07e-1daf-486a-8508-eba1b7b0acf7",
   "metadata": {},
   "source": [
    "''' \n",
    "THIS CELL HAS A LONG RUNTIME\n",
    "    By using this command I determined that the model seems to work best when\n",
    "    using kernel size 32 for layer 1, kernel size 16 for layer 2, and no layer 3.\n",
    "    Moving forward I will use this CNN configuration to cross-validate and choose hyperparameters\n",
    "'''\n",
    "def choose_CNN(l1, l2, l3):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(l1, (3, 3), activation='relu', input_shape=(288, 432, 4)))\n",
    "    if l2 != None:\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(l2, (3, 3), activation='relu'))\n",
    "    if l3 != None:\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(l3, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    history = model.fit(X_images_train_tens, y_images_train_tens, epochs=10, validation_data=(X_images_val_tens, y_images_val_tens))\n",
    "    return model\n",
    "\n",
    "'''Train and test CNN'''\n",
    "X_images_train_tens = tf.convert_to_tensor(X_images_train, dtype=float)\n",
    "y_images_train_tens = tf.convert_to_tensor(y_images_train.astype(np.float32), dtype=float)\n",
    "X_images_val_tens = tf.convert_to_tensor(X_images_val, dtype=float)\n",
    "y_images_val_tens = tf.convert_to_tensor(y_images_val.astype(np.float32), dtype=float)\n",
    "\n",
    "layer1 = [16,32,64]\n",
    "layer2 = [None,16,32]\n",
    "layer3 = [None,16,32]\n",
    "allModels = []\n",
    "\n",
    "for l1 in layer1:\n",
    "    for l2 in layer2:\n",
    "        for l3 in layer3:\n",
    "            allModels.append(choose_CNN(l1,l2,l3))\n",
    "\n",
    "for m in allModels:\n",
    "    m.evaluate(X_images_val_tens,  y_images_val_tens, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "THIS CELL HAS A LONG RUNTIME\n",
    "    By using this command I determined that the best optimizer for nearly all amounts of epochs was adamax\n",
    "    Adamax performed best at 10 epochs\n",
    "'''\n",
    "def train_test_cnn(opt,epch):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(288, 432, 4)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10),\n",
    "    ])\n",
    "    model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    model.fit(X_images_train_tens, y_images_train_tens, epochs=epch)\n",
    "    _, accuracy = model.evaluate(X_images_val_tens, y_images_val_tens)\n",
    "    return accuracy\n",
    "\n",
    "# Convert spectrograms to tensors\n",
    "X_images_train_tens = tf.convert_to_tensor(X_images_train, dtype=float)\n",
    "y_images_train_tens = tf.convert_to_tensor(y_images_train.astype(np.float32), dtype=float)\n",
    "X_images_val_tens = tf.convert_to_tensor(X_images_val, dtype=float)\n",
    "y_images_val_tens = tf.convert_to_tensor(y_images_val.astype(np.float32), dtype=float)\n",
    "\n",
    "# Set up cross-validation and choose hyperparameters\n",
    "OPTIMIZER = ['adam','adamax','ftrl','rmsprop','sgd']\n",
    "EPOCHS = [5,10,20,30,40]\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for optimizer in OPTIMIZER:\n",
    "    for epoch in EPOCHS:\n",
    "        tempAcc = train_test_cnn(optimizer, epoch)\n",
    "        outputs.append('Trial Number: ' + str(session_num) + \n",
    "                        '\\nOptimizer: ' + optimizer + \n",
    "                        '\\nEpochs: ' + str(epoch) +\n",
    "                        '\\nAccuracy: ' + str(tempAcc))\n",
    "        session_num += 1\n",
    "    \n",
    "for result in outputs:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44917cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
